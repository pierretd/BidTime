{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avazu CTR Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Specifying the necessary imports'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import sklearn\n",
    "import matplotlib.dates as mdates\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import f1_score, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ignore Warning Messages'''\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Set style to GGplot for asthetics'''\n",
    "matplotlib.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Helper function for date column which will be passed in when we import dataset'''\n",
    "parse_date = lambda val : pd.datetime.strptime(val, '%y%m%d%H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Sample from Training Data down to 1 million records'''\n",
    "\n",
    "n = 40428966  #total number of records in the clickstream data \n",
    "sample_size = 100000\n",
    "skip_values = sorted(random.sample(range(1,n), n-sample_size)) \n",
    "\n",
    "#Tracking the indices of rows to be skipped at random in the next stage i.e the LOADING stage \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Memory optimization-by changing the int32 to int64-massiely reduced the size of the dataset for faster proccessing\n",
    "'''\n",
    "data_types = {\n",
    "    'id': np.str,\n",
    "    'click': np.bool_,\n",
    "    'hour': np.str,\n",
    "    'C1': np.uint16,\n",
    "    'banner_pos': np.uint16,\n",
    "    'site_id': np.object,\n",
    "    'site_domain': np.object,\n",
    "    'site_category': np.object,\n",
    "    'app_id': np.object,\n",
    "    'app_domain': np.object,\n",
    "    'app_category': np.object,\n",
    "    'device_id': np.object,\n",
    "    'device_ip': np.object,\n",
    "    'device_model': np.object,\n",
    "    'device_type': np.uint16,\n",
    "    'device_conn_type': np.uint16,\n",
    "    'C14': np.uint16,\n",
    "    'C15': np.uint16,\n",
    "    'C16': np.uint16,\n",
    "    'C17': np.uint16,\n",
    "    'C18': np.uint16,\n",
    "    'C19': np.uint16,\n",
    "    'C20': np.uint16,\n",
    "    'C21': np.uint16\n",
    "}\n",
    "\n",
    "train_data = pd.read_csv('train.csv', parse_dates = ['hour'],\n",
    "                        date_parser = parse_date, skiprows = skip_values , \n",
    "                        dtype = data_types )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create a separate data frame where clicks = 1'''\n",
    "\n",
    "train_data_clicks = train_data[train_data['click']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Click through rate for entire dataset'''\n",
    "rows = train_data.shape[0]\n",
    "\n",
    "click_through_rate = train_data['click'].value_counts()/rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                  100001\n",
       "unique                    240\n",
       "top       2014-10-22 09:00:00\n",
       "freq                     1102\n",
       "first     2014-10-21 00:00:00\n",
       "last      2014-10-30 23:00:00\n",
       "Name: hour, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Dataset ranges from 2014-10-21 to 2014-10-30-about 9 days'''\n",
    "train_data.hour.describe() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Impressions V/S Clicks'''\n",
    "\n",
    "df_impressions = train_data.groupby('hour').agg({'click':'sum'})\n",
    "\n",
    "df_click = train_data[train_data['click']==1]\n",
    "\n",
    "temp_click = df_click.groupby('hour').agg({'click' : 'sum'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Create 3 new features based on the results from the cell above\n",
    "     1. hour_in_day-The hour of the event\n",
    "     2. weekday -- What day was the ad clicked\n",
    "     3. Day_name -- Take the specific day from hour\n",
    "'''\n",
    "\n",
    "train_data['hour_in_day'] = train_data['hour'].apply(lambda val : val.hour)\n",
    "train_data_clicks['hour_in_day'] = train_data_clicks['hour'].apply(lambda val : val.hour)\n",
    "\n",
    "train_data['weekday'] = train_data['hour'].apply(lambda val: val.dayofweek)\n",
    "train_data_clicks['weekday'] = train_data_clicks['hour'].apply(lambda val: val.dayofweek)\n",
    "\n",
    "train_data['day_name'] = train_data['hour'].apply(lambda x: x.strftime('%A'))\n",
    "train_data_clicks['day_name'] = train_data_clicks['hour'].apply(lambda x: x.strftime('%A'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'click', 'hour', 'C1', 'banner_pos', 'site_id', 'site_domain',\n",
       "       'site_category', 'app_id', 'app_domain', 'app_category', 'device_id',\n",
       "       'device_ip', 'device_model', 'device_type', 'device_conn_type', 'C14',\n",
       "       'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'hour_in_day',\n",
       "       'weekday', 'day_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create a new dataframe from hour'''\n",
    "\n",
    "hour_df = pd.DataFrame() \n",
    "\n",
    "hour_df['hr'] = train_data_clicks[['hour_in_day','click']].groupby(['hour_in_day']).count().reset_index().sort_values('click',ascending=False)['hour_in_day']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Cicks vs hour'''\n",
    "\n",
    "hour_df['pos_clicks'] = train_data_clicks[['hour_in_day','click']].groupby(['hour_in_day']).count().reset_index().sort_values('click',ascending=False)['click']\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Clicks and impressions vs hours'''\n",
    "\n",
    "hour_df['impressions_total'] = train_data[['hour_in_day','click']].groupby(['hour_in_day']).count().reset_index().sort_values('click',ascending=False)['click']\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create click through rate column-multiply by 100 for percentages\n",
    "'''\n",
    "\n",
    "hour_df['click_through_rate'] = 100*hour_df['pos_clicks']/hour_df['impressions_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_temp = train_data[['device_type','click']].groupby(['device_type','click'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_features = ['app_id', 'app_domain', 'app_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create area feature-subtraction gives best results'''\n",
    "train_data['area'] = train_data['C15']-train_data['C16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create others variable to capture the variety of site category'''\n",
    "train_data['site_category'] = train_data['site_category'].apply(lambda x: 'others' if x not in ['50e219e0','f028772b','28905ebd','3e814130'] else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create others for app category as well'''\n",
    "\n",
    "train_data['app_category'] = train_data['app_category'].apply(lambda x: 'others' if x not in ['07d7df22', '0f2161f8'] else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = ['weekday', 'hour_in_day',\n",
    "                  'banner_pos', 'site_category',\n",
    "                  'device_conn_type', 'app_category',\n",
    "                  'device_type', 'area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_target = 'click'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Use a sample for processing-total entries is 30,000'''\n",
    "train_model = train_data[model_features+[model_target]].sample(frac=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''One hot encode features for modeling'''\n",
    "def one_hot_features(data_frame, feature_set):\n",
    "    new_data_frame = pd.get_dummies(data_frame,\n",
    "                                     columns = feature_set,\n",
    "                                    sparse = True)\n",
    "\n",
    "    return new_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = one_hot_features(train_model,\n",
    "                                ['site_category',\n",
    "                                 'app_category',\n",
    "                                 'banner_pos'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = np.array(train_model.columns[train_model.columns!=model_target].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(random_state=42, solver='lbfgs',\n",
    "                         multi_class='ovr').fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_clf.predict(x_valid)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2529    0]\n",
      " [ 471    0]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(metrics.roc_auc_score(y_valid, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.843\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=500),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=500,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdt_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bdt.predict(x_valid)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2389  140]\n",
      " [ 437   34]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5084144937829458\n"
     ]
    }
   ],
   "source": [
    "print(metrics.roc_auc_score(y_valid, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8076666666666666\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create test train split for XGboost'''\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    train_model[model_features].values,\n",
    "    train_model[model_target].values,\n",
    "    test_size=0.3,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(max_depth=1000, n_estimators=200, objective=\"rank:pairwise\", feature_selector=\"cyclic\")\n",
    "xgb_clf = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.555857\n",
      "Will train until validation_0-auc hasn't improved in 100 rounds.\n",
      "[1]\tvalidation_0-auc:0.557561\n",
      "[2]\tvalidation_0-auc:0.558001\n",
      "[3]\tvalidation_0-auc:0.558198\n",
      "[4]\tvalidation_0-auc:0.559687\n",
      "[5]\tvalidation_0-auc:0.55905\n",
      "[6]\tvalidation_0-auc:0.559393\n",
      "[7]\tvalidation_0-auc:0.558297\n",
      "[8]\tvalidation_0-auc:0.556325\n",
      "[9]\tvalidation_0-auc:0.556841\n",
      "[10]\tvalidation_0-auc:0.556184\n",
      "[11]\tvalidation_0-auc:0.555977\n",
      "[12]\tvalidation_0-auc:0.554887\n",
      "[13]\tvalidation_0-auc:0.55436\n",
      "[14]\tvalidation_0-auc:0.553196\n",
      "[15]\tvalidation_0-auc:0.553053\n",
      "[16]\tvalidation_0-auc:0.552482\n",
      "[17]\tvalidation_0-auc:0.55293\n",
      "[18]\tvalidation_0-auc:0.553518\n",
      "[19]\tvalidation_0-auc:0.552616\n",
      "[20]\tvalidation_0-auc:0.552182\n",
      "[21]\tvalidation_0-auc:0.553295\n",
      "[22]\tvalidation_0-auc:0.552929\n",
      "[23]\tvalidation_0-auc:0.552948\n",
      "[24]\tvalidation_0-auc:0.552928\n",
      "[25]\tvalidation_0-auc:0.553431\n",
      "[26]\tvalidation_0-auc:0.553153\n",
      "[27]\tvalidation_0-auc:0.552878\n",
      "[28]\tvalidation_0-auc:0.55263\n",
      "[29]\tvalidation_0-auc:0.553064\n",
      "[30]\tvalidation_0-auc:0.553542\n",
      "[31]\tvalidation_0-auc:0.553374\n",
      "[32]\tvalidation_0-auc:0.553359\n",
      "[33]\tvalidation_0-auc:0.553397\n",
      "[34]\tvalidation_0-auc:0.553124\n",
      "[35]\tvalidation_0-auc:0.553206\n",
      "[36]\tvalidation_0-auc:0.552894\n",
      "[37]\tvalidation_0-auc:0.55256\n",
      "[38]\tvalidation_0-auc:0.552414\n",
      "[39]\tvalidation_0-auc:0.552463\n",
      "[40]\tvalidation_0-auc:0.553055\n",
      "[41]\tvalidation_0-auc:0.553031\n",
      "[42]\tvalidation_0-auc:0.55293\n",
      "[43]\tvalidation_0-auc:0.552806\n",
      "[44]\tvalidation_0-auc:0.553301\n",
      "[45]\tvalidation_0-auc:0.553178\n",
      "[46]\tvalidation_0-auc:0.553588\n",
      "[47]\tvalidation_0-auc:0.553814\n",
      "[48]\tvalidation_0-auc:0.554493\n",
      "[49]\tvalidation_0-auc:0.554504\n",
      "[50]\tvalidation_0-auc:0.554631\n",
      "[51]\tvalidation_0-auc:0.554893\n",
      "[52]\tvalidation_0-auc:0.554884\n",
      "[53]\tvalidation_0-auc:0.554994\n",
      "[54]\tvalidation_0-auc:0.55478\n",
      "[55]\tvalidation_0-auc:0.555288\n",
      "[56]\tvalidation_0-auc:0.554821\n",
      "[57]\tvalidation_0-auc:0.554878\n",
      "[58]\tvalidation_0-auc:0.554591\n",
      "[59]\tvalidation_0-auc:0.554676\n",
      "[60]\tvalidation_0-auc:0.554965\n",
      "[61]\tvalidation_0-auc:0.55467\n",
      "[62]\tvalidation_0-auc:0.555056\n",
      "[63]\tvalidation_0-auc:0.555004\n",
      "[64]\tvalidation_0-auc:0.555358\n",
      "[65]\tvalidation_0-auc:0.555257\n",
      "[66]\tvalidation_0-auc:0.555614\n",
      "[67]\tvalidation_0-auc:0.555726\n",
      "[68]\tvalidation_0-auc:0.556006\n",
      "[69]\tvalidation_0-auc:0.555937\n",
      "[70]\tvalidation_0-auc:0.555717\n",
      "[71]\tvalidation_0-auc:0.556056\n",
      "[72]\tvalidation_0-auc:0.556183\n",
      "[73]\tvalidation_0-auc:0.55615\n",
      "[74]\tvalidation_0-auc:0.556707\n",
      "[75]\tvalidation_0-auc:0.556367\n",
      "[76]\tvalidation_0-auc:0.556306\n",
      "[77]\tvalidation_0-auc:0.556098\n",
      "[78]\tvalidation_0-auc:0.555888\n",
      "[79]\tvalidation_0-auc:0.556136\n",
      "[80]\tvalidation_0-auc:0.555994\n",
      "[81]\tvalidation_0-auc:0.556026\n",
      "[82]\tvalidation_0-auc:0.556108\n",
      "[83]\tvalidation_0-auc:0.556398\n",
      "[84]\tvalidation_0-auc:0.556376\n",
      "[85]\tvalidation_0-auc:0.555893\n",
      "[86]\tvalidation_0-auc:0.556684\n",
      "[87]\tvalidation_0-auc:0.556535\n",
      "[88]\tvalidation_0-auc:0.556211\n",
      "[89]\tvalidation_0-auc:0.555937\n",
      "[90]\tvalidation_0-auc:0.555784\n",
      "[91]\tvalidation_0-auc:0.555581\n",
      "[92]\tvalidation_0-auc:0.555525\n",
      "[93]\tvalidation_0-auc:0.555353\n",
      "[94]\tvalidation_0-auc:0.555054\n",
      "[95]\tvalidation_0-auc:0.555234\n",
      "[96]\tvalidation_0-auc:0.555231\n",
      "[97]\tvalidation_0-auc:0.555528\n",
      "[98]\tvalidation_0-auc:0.555363\n",
      "[99]\tvalidation_0-auc:0.555137\n",
      "[100]\tvalidation_0-auc:0.555128\n",
      "[101]\tvalidation_0-auc:0.55526\n",
      "[102]\tvalidation_0-auc:0.555122\n",
      "[103]\tvalidation_0-auc:0.554844\n",
      "[104]\tvalidation_0-auc:0.555151\n",
      "Stopping. Best iteration:\n",
      "[4]\tvalidation_0-auc:0.559687\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, feature_selector='cyclic', gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=1000,\n",
       "       min_child_weight=1, missing=None, n_estimators=200, n_jobs=1,\n",
       "       nthread=None, objective='rank:pairwise', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Run model with auc as eval metric'''\n",
    "xgb_clf.fit(x_train, y_train, early_stopping_rounds=100,\n",
    "            eval_metric=\"auc\", eval_set=[(x_valid, y_valid)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_clf.predict(x_valid)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1565  964]\n",
      " [ 253  218]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5408333396297219\n"
     ]
    }
   ],
   "source": [
    "print(metrics.roc_auc_score(y_valid, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5943333333333334\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model appears to perform when looking at the evaluation metrics, but the confusion matrix suggests otherwise. The Roc Auc score hovers around 50, which suggests the mdoel is not doing a good job of predicting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
